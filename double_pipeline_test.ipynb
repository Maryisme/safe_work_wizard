{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e7eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- WorkSafe Wizard (Final stable version): visible sources + hallucination guard ---\n",
    "import os\n",
    "import gradio as gr\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# ---------- Config ----------\n",
    "CHROMA_PATH = \"data/chroma\"\n",
    "LEGIS_COLLECTION = \"legislation_policy\"\n",
    "CASES_COLLECTION = \"legal_cases\"\n",
    "TOPK_A, TOPK_B = 8, 3\n",
    "BUDGET_A, BUDGET_B = 2500, 2000\n",
    "CAP_A, CAP_B = 900, 900\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"Set OPENAI_API_KEY before running this cell.\")\n",
    "\n",
    "# ---------- Chroma ----------\n",
    "ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-3-large\"  # must match ingestion dimension\n",
    ")\n",
    "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "collA = client.get_collection(name=LEGIS_COLLECTION, embedding_function=ef)\n",
    "collB = client.get_collection(name=CASES_COLLECTION, embedding_function=ef)\n",
    "\n",
    "def _format_source(meta):\n",
    "    \"\"\"Return a readable source reference.\"\"\"\n",
    "    url = meta.get(\"source_url\") or meta.get(\"url\")\n",
    "    fname = meta.get(\"filename\", \"\")\n",
    "    if url:\n",
    "        return \"Source: \" + fname + \" — \" + url\n",
    "    return \"Source: \" + fname\n",
    "\n",
    "def _retrieve(collection, query, k, max_chars, per_chunk_cap, prefix):\n",
    "    \"\"\"Retrieve top chunks with truncation and label them.\"\"\"\n",
    "    try:\n",
    "        res = collection.query(query_texts=[query], n_results=k)\n",
    "    except Exception as e:\n",
    "        return \"[\" + prefix + \"1] Retrieval failed: \" + str(e), 0\n",
    "    if not res.get(\"ids\") or not res[\"ids\"][0]:\n",
    "        return \"\", 0\n",
    "    items, total = [], 0\n",
    "    for i in range(len(res[\"ids\"][0])):\n",
    "        text = (res[\"documents\"][0][i] or \"\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        if len(text) > per_chunk_cap:\n",
    "            text = text[:per_chunk_cap]\n",
    "        meta = res[\"metadatas\"][0][i] or {}\n",
    "        label = \"[\" + prefix + str(len(items)+1) + \" \" + meta.get(\"filename\",\"\") + \"#\" + str(meta.get(\"chunk_index\", i)) + \"]\"\n",
    "        src = _format_source(meta)\n",
    "        chunk_text = label + \"\\n\" + src + \"\\n\" + text\n",
    "        items.append(chunk_text)\n",
    "        total += len(text)\n",
    "        if total >= max_chars:\n",
    "            break\n",
    "    return \"\\n\\n\".join(items), len(items)\n",
    "\n",
    "def _build_prompt(user_situation, A_block, B_block, has_cases):\n",
    "    \"\"\"Constructs system and user messages cleanly.\"\"\"\n",
    "    system = (\n",
    "        \"You are a BC workplace triage explainer. \"\n",
    "        \"Use legislation/policy excerpts to assess whether the described conduct likely qualifies as bullying or harassment. \"\n",
    "        \"Base your analysis ONLY on the Legislation Excerpts (Section A). \"\n",
    "        \"List exact sources you rely on by name/URL as shown in the excerpts. \"\n",
    "        \"If NO case excerpts are provided, OMIT the 'Similar Tribunal Decisions' section entirely. \"\n",
    "        \"If case excerpts are provided, you may include a brief 'Similar Tribunal Decisions' section using ONLY those case excerpts; \"\n",
    "        \"do not invent or imply the existence of other cases. \"\n",
    "        \"Never invent sources or citations.\"\n",
    "    )\n",
    "\n",
    "    section_b = \"\"\n",
    "    if has_cases and B_block.strip():\n",
    "        section_b = (\n",
    "            \"\\n\\nSection B — Case Excerpts (context only; do not change your decision based on these):\\n---\\n\"\n",
    "            + B_block\n",
    "        )\n",
    "\n",
    "    user = (\n",
    "        \"User Situation:\\n---\\n\" + user_situation.strip() + \"\\n\\n\"\n",
    "        \"Section A — Legislation Excerpts (authoritative; use these to assess and justify):\\n---\\n\"\n",
    "        + (A_block.strip() if A_block.strip() else \"(none retrieved)\")\n",
    "        + section_b\n",
    "        + \"\\n\\nYour tasks:\\n\"\n",
    "        \"1) Assessment under the Law & Policy (use ONLY Section A):\\n\"\n",
    "        \"   - Return one of: 'very likely', 'likely', 'borderline', or 'unlikely'.\\n\"\n",
    "        \"   - Provide 3–5 bullets mapping the user's facts to legal elements. Quote sparingly and refer to the provided sources by name/URL.\\n\"\n",
    "        \"2) Confidence: repeat the likelihood from #1.\\n\"\n",
    "    )\n",
    "\n",
    "    if has_cases:\n",
    "        user += (\n",
    "            \"3) Similar Tribunal Decisions (context only): list 1–3 items drawn ONLY from the case excerpts above; \"\n",
    "            \"1–2 lines each; include outcome; cite by the provided source names/URLs.\\n\"\n",
    "        )\n",
    "    else:\n",
    "        user += \"3) Do not include a 'Similar Tribunal Decisions' section (no case excerpts were provided).\\n\"\n",
    "\n",
    "    user += (\n",
    "        \"4) Next Steps: 3–5 actionable steps consistent with your assessment.\\n\"\n",
    "        \"5) Sources: list the specific Section A sources (by name/URL) you relied on.\\n\"\n",
    "        \"6) Disclaimer: one line that this is general information, not legal advice.\"\n",
    "    )\n",
    "\n",
    "    return {\"system\": system, \"user\": user}\n",
    "\n",
    "def _call_llm(prompt):\n",
    "    \"\"\"Calls OpenAI chat completion.\"\"\"\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt[\"user\"]},\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=900,\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return \"**LLM call failed:** \" + str(e)\n",
    "\n",
    "def triage(user_text):\n",
    "    \"\"\"Main pipeline: retrieve → build prompt → call LLM.\"\"\"\n",
    "    if not user_text or not user_text.strip():\n",
    "        return \"Please paste the user's situation.\"\n",
    "\n",
    "    query_A = \"bullying harassment definition repeated one serious incident reasonable management action WorkSafeBC\"\n",
    "    query_B = \"supervisor yelling insults repeated humiliation intimidation decision outcome\"\n",
    "\n",
    "    A_block, _ = _retrieve(collA, query_A, TOPK_A, BUDGET_A, CAP_A, prefix=\"A\")\n",
    "    B_block, nB = _retrieve(collB, query_B, TOPK_B, BUDGET_B, CAP_B, prefix=\"B\")\n",
    "\n",
    "    prompt = _build_prompt(user_text, A_block, B_block, has_cases=(nB > 0))\n",
    "    return _call_llm(prompt)\n",
    "\n",
    "# ---------- Gradio UI ----------\n",
    "demo = gr.Interface(\n",
    "    fn=triage,\n",
    "    inputs=gr.Textbox(lines=8, label=\"Describe the situation\"),\n",
    "    outputs=gr.Markdown(label=\"Assessment\"),\n",
    "    title=\"WorkSafe Wizard — Minimal Triage\",\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "demo.launch(share=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
