{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebc9c8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Set OPENAI_API_KEY in your environment or in this cell.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m TOP_K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OPENAI_API_KEY:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet OPENAI_API_KEY in your environment or in this cell.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OPENAI_API_KEY\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Set OPENAI_API_KEY in your environment or in this cell."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Required\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "\n",
    "# Paths / names\n",
    "CHROMA_PATH = \"data/chroma\"          # your persistent Chroma directory\n",
    "COLLECTION_NAME = \"legal_cases\"      # change if you used a different collection name\n",
    "\n",
    "# Models\n",
    "EMBED_MODEL = \"text-embedding-3-large\"  # must match what you used to build the DB\n",
    "CHAT_MODEL = \"gpt-4o-mini\"              # any chat-capable model is fine\n",
    "\n",
    "# Retrieval\n",
    "TOP_K = 5\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"Set OPENAI_API_KEY in your environment or in this cell.\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Chroma persistent client and collection\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "try:\n",
    "    collection = chroma_client.get_collection(COLLECTION_NAME)\n",
    "except Exception:\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        COLLECTION_NAME, metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "print(\"Connected to Chroma collection:\", collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc77944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, top_k: int = TOP_K):\n",
    "    \"\"\"\n",
    "    Embeds the query with text-embedding-3-large and queries Chroma.\n",
    "    Returns (context_text, citations_list).\n",
    "    \"\"\"\n",
    "    # 1) Embed query\n",
    "    emb = client.embeddings.create(model=EMBED_MODEL, input=query).data[0].embedding\n",
    "\n",
    "    # 2) Query Chroma\n",
    "    res = collection.query(\n",
    "        query_embeddings=[emb],\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "    docs  = (res.get(\"documents\")  or [[]])[0]\n",
    "    metas = (res.get(\"metadatas\")  or [[]])[0]\n",
    "    dists = (res.get(\"distances\")  or [[]])[0]\n",
    "\n",
    "    # 3) Build context and simple citations\n",
    "    blocks, cites = [], []\n",
    "    for i, (doc, md, dist) in enumerate(zip(docs, metas, dists)):\n",
    "        md = md or {}\n",
    "        source = md.get(\"source\", \"unknown\")\n",
    "        chunk_idx = md.get(\"chunk_index\", i)\n",
    "        start = md.get(\"start_char\")\n",
    "        end = md.get(\"end_char\")\n",
    "        tag = f\"[{source}#chunk{chunk_idx}]\"\n",
    "        blocks.append(f\"{tag}\\n{doc}\")\n",
    "        if start is not None and end is not None:\n",
    "            cites.append(f\"{tag}({start}-{end})\")\n",
    "        else:\n",
    "            cites.append(tag)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join(blocks)\n",
    "    return context_text, cites\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
